---
title: "Why Use Agent Contracts?"
description: "Understanding the benefits and challenges of AI agents, and how Agent Contracts solve them"
---

## The Problem: Why AI Agents Are Hard to Control

AI agents can plan, reason, use tools, and act autonomously, making them powerful and versatile. However, their flexibility also makes them unpredictable and difficult to control compared to simple-prompt LLM applications or deterministic LLM pipelines.

### The Tradeoff Between Generality and Control

<img className="block dark:hidden" src="/images/tradeoff.png" alt="Prompting Tradeoff Light" />
<img className="hidden dark:block" src="/images/tradeoff.png" alt="Prompting Tradeoff Dark" />

Developers face a fundamental tradeoff: **generality vs. control**. The broader the agent's capabilities, the harder it is to ensure predictable behavior in specific situations.

For instance, a customer support agent designed to handle all inquiries requires broad prompts and access to many tools. However, this generality can make its behavior unpredictable in nuanced cases, such as a refund request where the customer is ineligible.

This forces most developers to choose between:
- **General agents** that lack reliable control.
- **Highly specialized agents** that are too rigid.

Neither approach is ideal for production systems, which require **both reliability and flexibility**.

## The Gap: What’s Missing in Current Approaches

Unlike traditional software, where behavior is explicitly defined in code, AI agents are primarily guided by prompts. However, prompts alone are:
- **Ambiguous and hard to tune** for all possible scenarios.
- **Not strictly followed** by LLMs, making enforcement difficult.
- **Either too broad (reducing control) or too narrow (limiting flexibility).**

### The Need for a Structured Yet Flexible Way to Define Agent Behavior

Currently, we cannot determine an AI agent’s full capabilities just from its prompts. We need a structured way to specify expected behavior in specific scenarios beyond broad natural language instructions in prompts.

## The Solution: Agent Contracts as a Complementary Approach

Agent Contracts introduce a **structured yet lightweight** way to refine agent behavior while maintaining flexibility. Unlike prompts, which provide general guidance, contracts **enhance and complement** them by capturing specific expectations in targeted scenarios.

### **How Agent Contracts Work**

1. **Define** – Clearly specify expected agent behavior in specific scenarios **without limiting adaptability**.
   - Contracts work alongside general prompts to provide additional structure where needed.
   - They are written in **natural language** like prompts but focus on specific situational requirements.
   - They ensure agents handle edge cases and critical workflows correctly **without excessive rigidity**.

2. **Evaluate** – Test agent behavior against predefined scenarios **to quantify the agent's behavior**.
   - Contracts include a **native verification system** to evaluate execution traces.
   - Developers can quickly **validate** how well an agent follows intended behavior.
   - Since contracts are scenario-based, they activate **only when relevant**, reducing the burden on prompts.

3. **Enforce** – Monitor and correct agent behavior in runtime without stifling autonomy.
   - Contracts act as **behavioral & business logic guardrails**, ensuring adherence while allowing adaptive problem-solving.
   - Unlike prompts, which apply at all times, contracts **activate dynamically** when agents encounter specific conditions.
   - Successful adherence builds trust by certifying correct execution **while preserving flexibility**.

<img className="block dark:hidden" src="/images/role-of-contracts.png" alt="Role of Contracts Light" />
<img className="hidden dark:block" src="/images/role-of-contracts.png" alt="Role of Contracts Dark" />

This illustration explains the role of contracts across two dimensions:
- **Known vs. unknown scenarios**
- **Working vs. non-working scenarios**

Without contracts, developers lack visibility into when an agent works or fails. Contracts:
- Expand the **known** set of working and failing scenarios **without rigid constraints**.
- Help diagnose issues through evaluation **while keeping agents adaptive**.
- Push the "works" boundary further by gently guiding behavior **rather than imposing hard limits**.

## Next Steps

Ready to build more reliable AI agents? Get started with our [Quick Start Guide](/quickstart) or explore the [Core Concepts](/core-concepts) to dive deeper.
